{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "train_labels_orig = train_labels\n",
    "valid_labels_orig = valid_labels\n",
    "test_labels_orig = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization For Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n",
      "0.8907\n",
      "0.8907\n"
     ]
    }
   ],
   "source": [
    "samples=100000\n",
    "C=1 #1e42\n",
    "\n",
    "lr = LogisticRegression(C=C)\n",
    "nsamples, img_shape = train_dataset.shape\n",
    "d2_train_dataset = train_dataset.reshape((nsamples,img_shape))[:samples]\n",
    "\n",
    "nsamples, img_shape = test_dataset.shape\n",
    "d2_test_dataset = test_dataset.reshape((nsamples,img_shape))[:samples]\n",
    "\n",
    "\n",
    "print(train_labels[:samples].shape)\n",
    "lr.fit(d2_train_dataset,train_labels_orig[:samples])\n",
    "y_pred = lr.predict(d2_test_dataset)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_pred, test_labels_orig[:samples]))\n",
    "print(metrics.f1_score(y_pred, test_labels_orig[:samples], average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularization For Neural Net without hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = 10000\n",
    "beta=0.07\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    logits = tf.matmul(train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=train_labels, logits=logits))\n",
    "    # Test accuracy: 83.9% w/o regularization\n",
    "    loss=loss+tf.multiply(beta, tf.nn.l2_loss(weights))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 233.981430\n",
      "Validation accuracy: 10.6%\n",
      "Loss at step 100: 1.082748\n",
      "Validation accuracy: 81.1%\n",
      "Loss at step 200: 0.931287\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 300: 0.930516\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 400: 0.930312\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 500: 0.930240\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 600: 0.930207\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 700: 0.930197\n",
      "Validation accuracy: 81.0%\n",
      "Loss at step 800: 0.930194\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 87.9%\n",
      "Total Time=0:26:58.554839\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "tot = str(datetime.now()-start)\n",
    "print(\"Total Time={}\".format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the overfitting, the train data will show high accuracy in compare to validation and the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x, drop=False):\n",
    "    l1 = tf.add(tf.matmul(x,  w1), b1)\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    if drop:\n",
    "        l1 = tf.nn.dropout(l1, 0.5)\n",
    "    outer = tf.add(tf.matmul(l1, w_outer), bias_outer)\n",
    "    \n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = 5000\n",
    "hidden_layers_size = 500\n",
    "beta=0.07\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layers_size]))\n",
    "    w_outer = tf.Variable(tf.truncated_normal((hidden_layers_size, num_labels)))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([hidden_layers_size])),\n",
    "    bias_outer = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    logits = network(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction =  tf.nn.softmax(network(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(network(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 284.583069\n",
      "Training accuracy: 5.7%\n",
      "Validation accuracy: 19.2%\n",
      "Loss at step 100: 10.527025\n",
      "Training accuracy: 81.4%\n",
      "Validation accuracy: 73.2%\n",
      "Loss at step 200: 4.360045\n",
      "Training accuracy: 87.9%\n",
      "Validation accuracy: 73.0%\n",
      "Loss at step 300: 1.364158\n",
      "Training accuracy: 94.6%\n",
      "Validation accuracy: 72.9%\n",
      "Loss at step 400: 0.390220\n",
      "Training accuracy: 97.2%\n",
      "Validation accuracy: 73.2%\n",
      "Loss at step 500: 0.089656\n",
      "Training accuracy: 99.1%\n",
      "Validation accuracy: 73.1%\n",
      "Loss at step 600: 0.024793\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 73.0%\n",
      "Loss at step 700: 0.012456\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 73.0%\n",
      "Loss at step 800: 0.006092\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 73.1%\n",
      "Test accuracy: 81.7%\n",
      "Total Time=0:08:14.957490\n"
     ]
    }
   ],
   "source": [
    "num_steps=801\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "tot = str(datetime.now()-start)\n",
    "print(\"Total Time={}\".format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    w1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layers_size]))\n",
    "    w_outer = tf.Variable(tf.truncated_normal((hidden_layers_size, num_labels)))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([hidden_layers_size])),\n",
    "    bias_outer = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = network(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = network(tf_valid_dataset)\n",
    "    test_prediction = network(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 246.792252\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 20.1%\n",
      "Minibatch loss at step 500: 9.072532\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 10.204161\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1500: 3.586279\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2000: 3.753148\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 3.479273\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 2.818547\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.7%\n",
      "Test accuracy: 88.9%\n",
      "Total Time=0:01:49.846983\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "tot = str(datetime.now()-start)\n",
    "print(\"Total Time={}\".format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = 5000\n",
    "hidden_layers_size = 500\n",
    "beta=0.07\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layers_size]))\n",
    "    w_outer = tf.Variable(tf.truncated_normal((hidden_layers_size, num_labels)))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([hidden_layers_size])),\n",
    "    bias_outer = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    logits = network(tf_train_dataset, True)\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction =  tf.nn.softmax(network(tf_valid_dataset, True))\n",
    "    test_prediction = tf.nn.softmax(network(tf_test_dataset, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 322.726685\n",
      "Training accuracy: 11.9%\n",
      "Validation accuracy: 18.2%\n",
      "Loss at step 100: 32.135086\n",
      "Training accuracy: 74.9%\n",
      "Validation accuracy: 72.2%\n",
      "Loss at step 200: 19.821112\n",
      "Training accuracy: 78.4%\n",
      "Validation accuracy: 72.9%\n",
      "Loss at step 300: 13.313540\n",
      "Training accuracy: 81.0%\n",
      "Validation accuracy: 73.9%\n",
      "Loss at step 400: 10.298458\n",
      "Training accuracy: 82.3%\n",
      "Validation accuracy: 74.5%\n",
      "Loss at step 500: 7.137795\n",
      "Training accuracy: 83.8%\n",
      "Validation accuracy: 74.8%\n",
      "Loss at step 600: 6.406398\n",
      "Training accuracy: 84.6%\n",
      "Validation accuracy: 74.8%\n",
      "Loss at step 700: 5.193758\n",
      "Training accuracy: 85.3%\n",
      "Validation accuracy: 75.2%\n",
      "Loss at step 800: 4.580975\n",
      "Training accuracy: 85.4%\n",
      "Validation accuracy: 75.3%\n",
      "Test accuracy: 82.6%\n",
      "Total Time=0:09:43.617356\n"
     ]
    }
   ],
   "source": [
    "num_steps=801\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "tot = str(datetime.now()-start)\n",
    "print(\"Total Time={}\".format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things can be done in addition to above:\n",
    "* Increase the train data subset\n",
    "* Increase number of steps\n",
    "* Try different activation functions\n",
    "* Dropout keep_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob=0.8\n",
    "def network_for_perf(x, drop=False):\n",
    "    l1 = tf.add(tf.matmul(x,  w1), b1)\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    #if drop:\n",
    "    l1 = tf.nn.dropout(l1, keep_prob)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1,  w2), b2)\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    l2 = tf.nn.dropout(l2, keep_prob)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2,  w3), b3)\n",
    "    l3 = tf.nn.relu(l3)\n",
    "#     l3 = tf.nn.dropout(l3, keep_prob)\n",
    "    outer = tf.add(tf.matmul(l2, w_outer), bias_outer)\n",
    "    \n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "hidden_layers_size = 512\n",
    "learn_rate=0.001\n",
    "\n",
    "# keep_prob=0.8\n",
    "# def network(x, drop=False):\n",
    "#     l1 = tf.add(tf.matmul(x,  w1), b1)\n",
    "#     l1 = tf.nn.relu(l1)\n",
    "#     #if drop:\n",
    "#     l1 = tf.nn.dropout(l1, keep_prob)\n",
    "    \n",
    "#     l2 = tf.add(tf.matmul(l1,  w2), b2)\n",
    "#     l2 = tf.nn.relu(l2)\n",
    "#     l2 = tf.nn.dropout(l2, keep_prob)\n",
    "    \n",
    "#     l3 = tf.add(tf.matmul(l2,  w3), b3)\n",
    "#     l3 = tf.nn.relu(l3)\n",
    "# #     l3 = tf.nn.dropout(l3, keep_prob)\n",
    "#     outer = tf.add(tf.matmul(l2, w_outer), bias_outer)\n",
    "    \n",
    "#     return outer\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    w1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layers_size]))\n",
    "    w2 = tf.Variable(tf.truncated_normal([hidden_layers_size, hidden_layers_size]))\n",
    "    w3 = tf.Variable(tf.truncated_normal([hidden_layers_size, hidden_layers_size]))\n",
    "    w_outer = tf.Variable(tf.truncated_normal((hidden_layers_size, num_labels)))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([hidden_layers_size]))\n",
    "    b2 = tf.Variable(tf.zeros([hidden_layers_size]))\n",
    "    b3 = tf.Variable(tf.zeros([hidden_layers_size]))\n",
    "    bias_outer = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = network(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n",
    "    optimizer = tf.train.RMSPropOptimizer(learn_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = network(tf_valid_dataset)\n",
    "    test_prediction = network(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 225.862457\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 13.2%\n",
      "Minibatch loss at step 500: 14.402805\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1000: 10.270929\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 9.312311\n",
      "Minibatch accuracy: 84.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2000: 9.883364\n",
      "Minibatch accuracy: 80.3%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 2500: 7.506279\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 3000: 5.894453\n",
      "Minibatch accuracy: 86.5%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 3500: 4.691394\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 4000: 3.955575\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 4500: 3.161830\n",
      "Minibatch accuracy: 87.1%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 5000: 4.413912\n",
      "Minibatch accuracy: 85.7%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 5500: 2.902763\n",
      "Minibatch accuracy: 88.9%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 6000: 3.262067\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 6500: 3.495181\n",
      "Minibatch accuracy: 87.1%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 7000: 1.843699\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 7500: 1.386166\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 8000: 1.861195\n",
      "Minibatch accuracy: 89.6%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 8500: 1.906935\n",
      "Minibatch accuracy: 92.6%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 9000: 2.003850\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 9500: 1.102413\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 10000: 1.493593\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 10500: 1.351775\n",
      "Minibatch accuracy: 90.4%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 11000: 1.182475\n",
      "Minibatch accuracy: 93.2%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 11500: 1.852424\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 12000: 1.215733\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 12500: 1.026165\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 13000: 0.733010\n",
      "Minibatch accuracy: 93.2%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 13500: 0.881014\n",
      "Minibatch accuracy: 93.6%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 14000: 1.191740\n",
      "Minibatch accuracy: 91.2%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 14500: 1.086401\n",
      "Minibatch accuracy: 91.8%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 15000: 0.924847\n",
      "Minibatch accuracy: 93.2%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 15500: 0.732590\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 16000: 0.709041\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 16500: 0.797502\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 17000: 1.117289\n",
      "Minibatch accuracy: 91.6%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 17500: 0.532808\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 18000: 0.682764\n",
      "Minibatch accuracy: 92.8%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 18500: 0.665915\n",
      "Minibatch accuracy: 93.6%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 19000: 0.545653\n",
      "Minibatch accuracy: 93.9%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 19500: 0.456054\n",
      "Minibatch accuracy: 95.1%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 20000: 0.825927\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 20500: 0.418972\n",
      "Minibatch accuracy: 94.9%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 21000: 0.564986\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 21500: 0.282620\n",
      "Minibatch accuracy: 95.9%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 22000: 0.194652\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 22500: 0.173875\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 23000: 0.292242\n",
      "Minibatch accuracy: 94.3%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 23500: 0.538490\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 24000: 0.393063\n",
      "Minibatch accuracy: 94.7%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 24500: 0.195309\n",
      "Minibatch accuracy: 95.5%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 25000: 0.368017\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 25500: 0.378363\n",
      "Minibatch accuracy: 95.1%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 26000: 0.065884\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 26500: 0.231807\n",
      "Minibatch accuracy: 96.3%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 27000: 0.467143\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 27500: 0.243404\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 28000: 0.559929\n",
      "Minibatch accuracy: 96.3%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 28500: 0.264560\n",
      "Minibatch accuracy: 96.3%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 29000: 0.165075\n",
      "Minibatch accuracy: 97.1%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 29500: 0.129561\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 30000: 0.241616\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 30500: 0.298247\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 31000: 0.096268\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 31500: 0.157507\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 32000: 0.275367\n",
      "Minibatch accuracy: 95.5%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 32500: 0.674470\n",
      "Minibatch accuracy: 95.9%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 33000: 0.217416\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 33500: 0.120125\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 34000: 0.190181\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 34500: 0.165263\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 35000: 0.243407\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 35500: 0.481262\n",
      "Minibatch accuracy: 94.3%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 36000: 0.212416\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 36500: 0.149886\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 37000: 0.140780\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 37500: 0.107628\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 38000: 0.212934\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 38500: 0.441271\n",
      "Minibatch accuracy: 95.9%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 39000: 0.153082\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 39500: 0.133540\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 40000: 0.095798\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 40500: 0.108935\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 41000: 0.045521\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 41500: 0.022275\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 42000: 0.119747\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 42500: 0.057829\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 43000: 0.296328\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 43500: 0.160736\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 44000: 0.329962\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 44500: 0.025213\n",
      "Minibatch accuracy: 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 45000: 0.029515\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 45500: 0.133680\n",
      "Minibatch accuracy: 97.1%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 46000: 0.059373\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 46500: 0.110743\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 47000: 0.100048\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 47500: 0.213561\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 48000: 0.091977\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 48500: 0.081661\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 49000: 0.122085\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 49500: 0.182003\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 50000: 0.046138\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 50500: 0.033274\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 51000: 0.112775\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 51500: 0.114411\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 52000: 0.061131\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 52500: 0.080863\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 53000: 0.099229\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 53500: 0.048115\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 54000: 0.087240\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 54500: 0.072552\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 55000: 0.103003\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 55500: 0.203518\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 56000: 0.042486\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 56500: 0.027159\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 57000: 0.084701\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 57500: 0.061347\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 58000: 0.088952\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 58500: 0.249229\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 59000: 0.083210\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 59500: 0.098794\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 60000: 0.105196\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 60500: 0.054281\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 61000: 0.242522\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 61500: 0.327680\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 62000: 0.312837\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 62500: 0.050368\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 63000: 0.050885\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 63500: 0.061720\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 64000: 0.224259\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 64500: 0.023436\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 65000: 0.142661\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 65500: 0.289173\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 66000: 0.156320\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 66500: 0.296754\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 67000: 0.040509\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 67500: 0.036105\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 68000: 0.238216\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 68500: 0.020499\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 69000: 0.061087\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 69500: 0.128829\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 70000: 0.012507\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 70500: 0.064854\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 71000: 0.115618\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 71500: 0.015039\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 72000: 0.094724\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 72500: 0.023948\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 73000: 0.040537\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 73500: 0.089381\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 74000: 0.021893\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 74500: 0.190062\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 75000: 0.110030\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 75500: 0.118620\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 76000: 0.041572\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 76500: 0.213282\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 77000: 0.045349\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 77500: 0.084138\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 78000: 0.097474\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 78500: 0.046433\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 79000: 0.105457\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 79500: 0.076752\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 80000: 0.427691\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 80500: 0.083415\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 81000: 0.407332\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 81500: 0.012660\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 82000: 0.138279\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 82500: 0.223192\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 83000: 0.161413\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 83500: 0.041675\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 84000: 0.049492\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 84500: 0.205110\n",
      "Minibatch accuracy: 97.1%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 85000: 0.160490\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 85500: 0.037780\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 86000: 0.044700\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 86500: 0.110639\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 87000: 0.080090\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 87500: 0.047409\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 88000: 0.154900\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 88500: 0.028303\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 89000: 0.006561\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 89500: 0.075609\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 90000: 0.184356\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 90500: 0.044278\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 91000: 0.017401\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 91500: 0.194648\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 92000: 0.053491\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 92500: 0.255068\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 93000: 0.051609\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 93500: 0.013404\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 94000: 0.153836\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 94500: 0.035006\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 95000: 0.120714\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 95500: 0.012105\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 96000: 0.028066\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 96500: 0.032892\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 97000: 0.103256\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 97500: 0.039655\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 98000: 0.006750\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 98500: 0.216411\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 99000: 0.033764\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 99500: 0.016025\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 100000: 0.013551\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 100500: 0.018047\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 101000: 0.123028\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 101500: 0.011963\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 102000: 0.070159\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 102500: 0.039643\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 103000: 0.299843\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 103500: 0.067193\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 104000: 0.018987\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 104500: 0.046912\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 105000: 0.243030\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 105500: 0.077051\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 106000: 0.069206\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 106500: 0.167685\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 107000: 0.080176\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 107500: 0.118622\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 108000: 0.241427\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 108500: 0.013522\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 109000: 0.076211\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 109500: 0.057468\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 110000: 0.223602\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 110500: 0.029746\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 111000: 0.020532\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 111500: 0.067348\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 112000: 0.116976\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 112500: 0.055604\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 113000: 0.054904\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 113500: 0.098079\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 114000: 0.034245\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 114500: 0.135294\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 115000: 0.039898\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 115500: 0.088856\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 116000: 0.028966\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 116500: 0.130125\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 117000: 0.121935\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 117500: 0.040448\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 118000: 0.059040\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 118500: 0.172408\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 119000: 0.469386\n",
      "Minibatch accuracy: 97.1%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 119500: 0.039292\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 120000: 0.152363\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 120500: 0.027071\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 121000: 0.034209\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 121500: 0.012251\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 122000: 0.015750\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 122500: 0.330263\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 123000: 0.034836\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 123500: 0.079907\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 124000: 0.326313\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 124500: 0.002312\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 125000: 0.154344\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 125500: 0.002475\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 126000: 0.054786\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 126500: 0.067482\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 127000: 0.201503\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 127500: 0.064586\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 128000: 0.033090\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 128500: 0.100482\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 129000: 0.021297\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 129500: 0.180126\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 130000: 0.046768\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 130500: 0.073636\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 131000: 0.008038\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 131500: 0.017502\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 132000: 0.019323\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 132500: 0.036217\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 133000: 0.148965\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 133500: 0.043069\n",
      "Minibatch accuracy: 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 134000: 0.057804\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 134500: 0.069904\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 135000: 0.153428\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 135500: 0.145979\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 136000: 0.045337\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 136500: 0.330663\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 137000: 0.446120\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 137500: 0.121217\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 138000: 0.154385\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 138500: 0.055644\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 139000: 0.017523\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 139500: 0.035821\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 140000: 0.129067\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 140500: 0.140175\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 141000: 0.036370\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 141500: 0.043273\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 142000: 0.221113\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 142500: 0.038921\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 143000: 0.107739\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 143500: 0.179142\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 144000: 0.069118\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 144500: 0.018325\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 145000: 0.250932\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 145500: 0.124414\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 146000: 0.001612\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 146500: 0.064006\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 147000: 0.174839\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 147500: 0.029459\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 148000: 0.013799\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 148500: 0.255149\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 149000: 0.097434\n",
      "Minibatch accuracy: 97.1%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 149500: 0.399190\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 150000: 0.202735\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 150500: 0.016598\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 151000: 0.055945\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 151500: 0.072054\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 152000: 0.020196\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 152500: 0.026178\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 153000: 0.116812\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 153500: 0.058751\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 154000: 0.013859\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 154500: 0.028607\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 155000: 0.080337\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 155500: 0.050965\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 156000: 0.092459\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 156500: 0.046452\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 157000: 0.020410\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 157500: 0.203040\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 158000: 0.081349\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 158500: 0.046058\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 159000: 0.015928\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 159500: 0.086688\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 160000: 0.182885\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 160500: 0.116838\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 161000: 0.460574\n",
      "Minibatch accuracy: 96.7%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 161500: 0.141270\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 162000: 0.276538\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 162500: 0.006290\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 163000: 0.165280\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 163500: 0.029753\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 164000: 0.082818\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 164500: 0.110546\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 165000: 0.012603\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 165500: 0.210020\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 166000: 0.053630\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 166500: 0.022073\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 167000: 0.188459\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 167500: 0.121644\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 168000: 0.037278\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 168500: 0.198595\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 169000: 0.001992\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 169500: 0.074112\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 170000: 0.088434\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 170500: 0.028074\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 171000: 0.147944\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 171500: 0.159212\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 172000: 0.037048\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 172500: 0.174009\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 173000: 0.011436\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 173500: 0.083798\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 174000: 0.162497\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 174500: 0.045040\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 175000: 0.096639\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 175500: 0.009246\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 176000: 0.146616\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 176500: 0.197291\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 177000: 0.260101\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 177500: 0.107292\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 178000: 0.165580\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 178500: 0.191682\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 179000: 0.167319\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 179500: 0.010885\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 180000: 0.054305\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 180500: 0.008995\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 181000: 0.038382\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 181500: 0.242934\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 182000: 0.079949\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 182500: 0.593189\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 183000: 0.123170\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 183500: 0.198609\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 184000: 0.019797\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 184500: 0.228970\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 185000: 0.025961\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 185500: 0.104397\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 186000: 0.002932\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 186500: 0.001369\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 187000: 0.014800\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 187500: 0.005887\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 188000: 0.026453\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 188500: 0.014252\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 189000: 0.000958\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 189500: 0.072176\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 190000: 0.148802\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 190500: 0.042949\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 191000: 0.471261\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 191500: 0.076688\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 192000: 0.065968\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 192500: 0.056468\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 193000: 0.021208\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 193500: 0.147859\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 194000: 0.018206\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 194500: 0.021675\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 195000: 0.003191\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 195500: 0.086903\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 196000: 0.060880\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 196500: 0.139822\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 197000: 0.031528\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 197500: 0.109615\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 198000: 0.452988\n",
      "Minibatch accuracy: 95.9%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 198500: 0.035419\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 199000: 0.025128\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 199500: 0.153165\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 200000: 0.044969\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 200500: 0.186725\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 201000: 0.051913\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 201500: 0.188350\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 202000: 0.082007\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 202500: 0.044327\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 203000: 0.210445\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 203500: 0.191857\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 204000: 0.072296\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 204500: 0.127189\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 205000: 0.318543\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 205500: 0.098569\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 206000: 0.030113\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 206500: 0.126436\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 207000: 0.059259\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 207500: 0.047336\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 208000: 0.028523\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 208500: 0.156816\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 209000: 0.207093\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 209500: 0.080385\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 210000: 0.072696\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 210500: 0.046773\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 211000: 0.091552\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 211500: 0.216321\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 212000: 0.619220\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 212500: 0.144093\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 213000: 0.048432\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 213500: 0.108233\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 214000: 0.047706\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 214500: 0.123765\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 215000: 0.049666\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 215500: 0.052136\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 216000: 0.022996\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 216500: 0.037444\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 217000: 0.025971\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 217500: 0.041563\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 218000: 0.037810\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 218500: 0.179217\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 219000: 0.058051\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 219500: 0.118785\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 220000: 0.044484\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 220500: 0.090973\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 221000: 0.003929\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 221500: 0.049497\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 222000: 0.269722\n",
      "Minibatch accuracy: 96.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 222500: 0.017186\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 223000: 0.043914\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 223500: 0.085754\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 224000: 0.092820\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 224500: 0.043600\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 225000: 0.088078\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 225500: 0.003360\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 226000: 0.110846\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 226500: 0.102320\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 227000: 0.041802\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 227500: 0.074250\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 228000: 0.142057\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 228500: 0.033421\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 229000: 0.024055\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 229500: 0.141283\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 230000: 0.020543\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 230500: 0.002016\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 231000: 0.034551\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 231500: 0.102423\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 232000: 0.118346\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 232500: 0.080317\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 233000: 0.003595\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 233500: 0.072984\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 234000: 0.004807\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 234500: 0.057718\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 235000: 0.353589\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 235500: 0.033991\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 236000: 0.054625\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 236500: 0.041617\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 237000: 0.017834\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 237500: 0.093400\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 238000: 0.002525\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 238500: 0.223449\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 239000: 0.063426\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 239500: 0.028330\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 240000: 0.092599\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 240500: 0.026391\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 241000: 0.010368\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 241500: 0.106680\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 242000: 0.187947\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 242500: 0.165106\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 243000: 0.167113\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 243500: 0.062972\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 244000: 0.072596\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 244500: 0.208483\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 245000: 0.200463\n",
      "Minibatch accuracy: 97.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 245500: 0.099938\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 246000: 0.094138\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 246500: 0.002399\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 247000: 0.057528\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 247500: 0.033568\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 248000: 0.039138\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 248500: 0.027377\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 249000: 0.002156\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 249500: 0.055777\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 250000: 0.022226\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 250500: 0.011033\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 251000: 0.175636\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 251500: 0.023436\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 252000: 0.105764\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 252500: 0.131837\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 253000: 0.106764\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 253500: 0.024361\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 254000: 0.007544\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 254500: 0.081470\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 255000: 0.170430\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 255500: 0.012859\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 256000: 0.068374\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 256500: 0.259590\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 257000: 0.111387\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 257500: 0.137739\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 258000: 0.036682\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 258500: 0.044743\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 259000: 0.140177\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 259500: 0.142631\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 260000: 0.088721\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 260500: 0.065569\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 261000: 0.055863\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 261500: 0.006091\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 262000: 0.013222\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 262500: 0.043768\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 263000: 0.221963\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 263500: 0.062879\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 264000: 0.035511\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 264500: 0.167746\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 265000: 0.012277\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 265500: 0.104413\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 266000: 0.034120\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 266500: 0.179574\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 267000: 0.005132\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 267500: 0.015259\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 268000: 0.398993\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 268500: 0.037991\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 269000: 0.289748\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 269500: 0.026957\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 270000: 0.011142\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 270500: 0.324073\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 271000: 0.003342\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 271500: 0.006886\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 272000: 0.000696\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 272500: 0.023963\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 273000: 0.038199\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 273500: 0.075602\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 274000: 0.033690\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 274500: 0.007298\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 275000: 0.355906\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 275500: 0.063211\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 276000: 0.035162\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 276500: 0.015052\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 277000: 0.032099\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 277500: 0.128460\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 278000: 0.003861\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 278500: 0.061244\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 279000: 0.037839\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 279500: 0.020368\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 280000: 0.105887\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 280500: 0.056063\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 281000: 0.053731\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 281500: 0.233075\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 282000: 0.101782\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 282500: 0.052769\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 283000: 0.182179\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 283500: 0.111848\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 284000: 0.070825\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 284500: 0.244331\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 285000: 0.027119\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 285500: 0.101488\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 286000: 0.055060\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 286500: 0.110790\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 287000: 0.004583\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 287500: 0.011375\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 288000: 0.027946\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 288500: 0.024569\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 289000: 0.068922\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 289500: 0.068908\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 290000: 0.003246\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 290500: 0.001183\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 291000: 0.209728\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 291500: 0.048959\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 292000: 0.036511\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 292500: 0.041323\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 293000: 0.107047\n",
      "Minibatch accuracy: 99.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 293500: 0.043778\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 294000: 0.031929\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 294500: 0.064352\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 295000: 0.247949\n",
      "Minibatch accuracy: 98.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 295500: 0.340029\n",
      "Minibatch accuracy: 98.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 296000: 0.275195\n",
      "Minibatch accuracy: 97.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 296500: 0.172166\n",
      "Minibatch accuracy: 99.0%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 297000: 0.018274\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 297500: 0.043997\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 298000: 0.001351\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 298500: 0.024580\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 299000: 0.215668\n",
      "Minibatch accuracy: 99.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 299500: 0.038940\n",
      "Minibatch accuracy: 99.8%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.8%\n",
      "Total Time=3:00:41.862077\n"
     ]
    }
   ],
   "source": [
    "num_steps = 300000\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "tot = str(datetime.now()-start)\n",
    "print(\"Total Time={}\".format(tot))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
